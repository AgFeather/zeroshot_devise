{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "image_channel = 3\n",
    "label_size = 150\n",
    "unknown_label_size = 50\n",
    "train_data_path = 'dataset/train_images'\n",
    "save_path = 'v_saved_model/'\n",
    "show_every_n = 10\n",
    "saved_every_n = 100\n",
    "train_step = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(object):\n",
    "    '''\n",
    "    使用给定的训练数据集训练一个AlexNet模型\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 batch_size=64,\n",
    "                 num_units = 128,\n",
    "                 num_classes = 150,\n",
    "                 learning_rate = 0.002,\n",
    "                 num_epoches = 1,\n",
    "                 is_training=True):\n",
    "\n",
    "        self.num_units = num_units\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epoches = num_epoches\n",
    "\n",
    "        if is_training:\n",
    "            self.batch_size = batch_size\n",
    "            self.drop_prob = 0.5\n",
    "        else:\n",
    "            self.batch_size = 1\n",
    "            self.drop_prob = 1.0\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def train_test_split(self, image_dataset, label_dataset):\n",
    "        train_x, test_x, train_y, test_y = \\\n",
    "            train_test_split(image_dataset, label_dataset, test_size=0.1)\n",
    "        return train_x, test_x,train_y, test_y\n",
    "\n",
    "    def get_batch(self):\n",
    "        for i in range(self.data_size // self.batch_size):\n",
    "            batch_x = self.train_x[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            batch_y = self.train_y[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            yield batch_x, batch_y\n",
    "\n",
    "    def build_input(self):\n",
    "        input_x = tf.placeholder(\n",
    "            tf.float32, [self.batch_size, image_size, image_size, image_channel], name='input_x')\n",
    "        output_y = tf.placeholder(tf.float32, [self.batch_size, self.num_classes], name='output_y')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='drop_keep')\n",
    "        return input_x, output_y, keep_prob\n",
    "\n",
    "    def bulid_CNN(self, input_x):\n",
    "        conv_layer1 = tf.layers.conv2d(inputs=input_x, filters=8, kernel_size=[8, 8],\n",
    "                                       strides=[2, 2], padding='SAME',activation=tf.nn.relu)\n",
    "        pooling_layer1 = tf.layers.max_pooling2d(\n",
    "            inputs=conv_layer1, pool_size=[2, 2], strides=[2, 2])\n",
    "\n",
    "        conv_layer2 = tf.layers.conv2d(inputs=pooling_layer1, filters=16, kernel_size=[4, 4],\n",
    "                                       strides=[2, 2], padding='SAME',activation=tf.nn.relu)\n",
    "        pooling_layer2 = tf.layers.max_pooling2d(\n",
    "            inputs=conv_layer2, pool_size=[2, 2], strides=[2, 2])\n",
    "\n",
    "        conv_layer3 = tf.layers.conv2d(inputs=pooling_layer2, filters=32, kernel_size=[4, 4],\n",
    "                                       strides=[2, 2], padding='SAME',activation=tf.nn.relu)\n",
    "        pooling_layer3 = tf.layers.max_pooling2d(\n",
    "            inputs=conv_layer3, pool_size=[2, 2], strides=[2, 2])\n",
    "        cnn_flat = tf.reshape(pooling_layer3, [self.batch_size, -1])\n",
    "        return cnn_flat\n",
    "\n",
    "    def bulid_full_connect(self, cnn_flat, keep_prob):\n",
    "        fc_layer1 = tf.layers.dense(inputs=cnn_flat, units=self.num_units, activation=tf.nn.relu)\n",
    "        fc_layer1 = tf.layers.dropout(fc_layer1, rate=keep_prob)\n",
    "        output_layer = tf.layers.dense(inputs=fc_layer1, units=self.num_classes, activation=None)\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "    def bulid_loss(self, logits, targets):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        return loss\n",
    "\n",
    "    def bulid_optimizer(self, loss):\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "        return optimizer\n",
    "\n",
    "    def bulid_accuracy(self, logits, targets):\n",
    "        equality = tf.equal(tf.argmax(logits, axis=1), tf.argmax(targets, axis=1))\n",
    "        equality = tf.cast(equality, tf.float32)\n",
    "        accuracy = tf.reduce_mean(equality)\n",
    "        return accuracy\n",
    "\n",
    "    def build_model(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.input_x, self.output_y, self.keep_prob = self.build_input()\n",
    "        self.cnn_padding = self.bulid_CNN(self.input_x)\n",
    "        self.output_layer = self.bulid_full_connect(self.cnn_padding, self.drop_prob)\n",
    "        self.repsentation = self.output_layer\n",
    "        self.loss = self.bulid_loss(self.output_layer, self.output_y)\n",
    "        self.optimizer = self.bulid_optimizer(self.loss)\n",
    "        self.accuracy = self.bulid_accuracy(self.output_layer, self.output_y)\n",
    "\n",
    "    def train(self, image_dataset, label_dataset):\n",
    "        self.train_x, self.test_x,self.train_y, self.test_y = \\\n",
    "            self.train_test_split(image_dataset, label_dataset)\n",
    "        self.data_size = len(self.train_x)  # 4510\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        #模型训练并将训练的结果保存在本地\n",
    "        with tf.Session() as sess:\n",
    "            print(\"AlexNet model training begins....\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            global_steps = 0\n",
    "            for epoch in range(self.num_epoches):\n",
    "                generator = self.get_batch()\n",
    "                for batch_x, batch_y in generator:\n",
    "                    global_steps += 1\n",
    "                    feed = {self.input_x: batch_x,\n",
    "                            self.output_y: batch_y,\n",
    "                            self.keep_prob: self.drop_prob}\n",
    "                    show_loss, show_accu, _ = sess.run(\n",
    "                        [self.loss, self.accuracy, self.optimizer], feed_dict=feed)\n",
    "\n",
    "                    if global_steps % show_every_n == 0:\n",
    "                        print('epoch: {}/{}..'.format(epoch+1, self.num_epoches),\n",
    "                              'global_step: {}..'.format(global_steps),\n",
    "                              'loss: {:.3f}..'.format(show_loss),\n",
    "                              'accuracy: {:.2f}..'.format(show_accu))\n",
    "\n",
    "                    if global_steps % saved_every_n == 0:\n",
    "                        saver.save(sess, save_path+\"e{}_s{}.ckpt\".format(epoch, global_steps))\n",
    "            saver.save(sess, save_path+\"lastest.ckpt\")\n",
    "\n",
    "        print('training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = utils.get_image_data()\n",
    "train_y = utils.get_one_hot_label_data()\n",
    "label2int, int2label = utils.get_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet model training begins....\n",
      "epoch: 1/2.. global_step: 10.. loss: 5.010.. accuracy: 0.00..\n",
      "epoch: 1/2.. global_step: 20.. loss: 5.006.. accuracy: 0.02..\n",
      "epoch: 1/2.. global_step: 30.. loss: 4.999.. accuracy: 0.00..\n",
      "epoch: 1/2.. global_step: 40.. loss: 5.010.. accuracy: 0.00..\n",
      "epoch: 1/2.. global_step: 50.. loss: 5.012.. accuracy: 0.00..\n",
      "epoch: 1/2.. global_step: 60.. loss: 5.016.. accuracy: 0.00..\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "model.train(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import visual_model\n",
    "import word_to_vec\n",
    "import utils\n",
    "\n",
    "image_repesentation_size = 150\n",
    "word_embedding_size = 200\n",
    "visual_model_checkpoints_dir = 'v_saved_model/'\n",
    "devise_model_checkpoints_dir = 'devise_saved_model/'\n",
    "word2vec_saved_dir = 'word2vec_saved/text8model.model'\n",
    "show_every_n = 200\n",
    "save_every_n = 1000\n",
    "num_label = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeViSE(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size=1,\n",
    "                 learning_rate=0.001):\n",
    "        self.alex_model = visual_model.AlexNet(is_training=False)\n",
    "        self.word_model = word_to_vec.get_word2vec()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.bulid_model()\n",
    "        print('devise model has been initialized')\n",
    "\n",
    "    def bulid_input(self):\n",
    "        input_x = tf.placeholder(dtype=tf.float32, shape=[image_repesentation_size, self.batch_size], name='input_x')\n",
    "        label_y = tf.placeholder(dtype=tf.float32, shape=[self.batch_size, word_embedding_size], name='output_y')\n",
    "        other_labels = tf.placeholder(dtype=tf.float32, shape=[self.batch_size, word_embedding_size], name='other_labels')\n",
    "        return input_x, label_y, other_labels\n",
    "\n",
    "    def bulid_linear_model(self, input_x, label_y, other_labels):\n",
    "        margin = 0.1\n",
    "        weight_matrix = tf.get_variable('weight_matrix', shape=[word_embedding_size, image_repesentation_size])\n",
    "        output_ = tf.matmul(weight_matrix, input_x)\n",
    "        loss1 = tf.reduce_sum(tf.matmul(label_y, output_))\n",
    "        loss2 = tf.reduce_sum(tf.matmul(other_labels, output_))\n",
    "        loss = tf.maximum(0.0, margin-loss1+loss2)\n",
    "        return output_, loss\n",
    "\n",
    "    def bulid_optimizer(self, loss):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
    "        return optimizer\n",
    "\n",
    "    def bulid_model(self):\n",
    "        self.input_x, self.output_y, self.other_labels = self.bulid_input()\n",
    "        self.prediction, self.loss = self.bulid_linear_model(self.input_x, self.output_y, self.other_labels)\n",
    "        self.optimizer = self.bulid_optimizer(self.loss)\n",
    "\n",
    "    def label_represent_set(self, label_data, int2label):\n",
    "        label_set = list(set(label_data))\n",
    "        label_set = [int2label[num] for num in label_set]\n",
    "        self.vec_set = []\n",
    "        for label in label_set:\n",
    "            vector = self.word_model[label]\n",
    "            self.vec_set.append(vector)\n",
    "\n",
    "\n",
    "    def train(self, image_data, label_data, int2label):\n",
    "        saver = tf.train.Saver()\n",
    "        self.word_model_wv = self.word_model.wv\n",
    "        with tf.Session() as sess:\n",
    "            global_step = 0\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for image, label in zip(image_data, label_data):\n",
    "                global_step += 1\n",
    "                image = np.array(image)\n",
    "                image = np.reshape(image, (1, 256, 256, 3))\n",
    "                feed = {self.alex_model.input_x: image}\n",
    "                image_representation = sess.run(self.alex_model.repsentation, feed_dict=feed)\n",
    "                image_representation = image_representation.T\n",
    "                label = int2label[label]\n",
    "                label = label.split('_')[0].lower()\n",
    "                if label in self.word_model_wv.vocab:\n",
    "                    label = self.word_model_wv[label]\n",
    "                else:\n",
    "                    label = self.word_model_wv['bird']\n",
    "                other_label = np.random.randint(0, num_label)\n",
    "                other_label = int2label[other_label]\n",
    "                other_label = other_label.split('_')[0].lower()\n",
    "                if other_label in self.word_model_wv.vocab:\n",
    "                    other_label = self.word_model_wv[other_label]\n",
    "                else:\n",
    "                    other_label = self.word_model_wv['bird']\n",
    "                other_label_representation = np.reshape(other_label, (1,200))\n",
    "                label_representation = np.reshape(label, (1, 200))\n",
    "\n",
    "                feed = {self.input_x: image_representation,\n",
    "                        self.output_y: label_representation,\n",
    "                        self.other_labels: other_label_representation}\n",
    "\n",
    "                show_loss, _ = sess.run([self.loss, self.optimizer], feed_dict=feed)\n",
    "\n",
    "                if global_step % show_every_n == 0 and show_loss > 0:\n",
    "                    print('step: {}'.format(global_step),\n",
    "                          'loss: {:.3f}'.format(show_loss))\n",
    "                if global_step % save_every_n == 0:\n",
    "                    saver.save(sess, devise_model_checkpoints_dir + 's{}.ckpt'.format(global_step))\n",
    "            saver.save(sess, devise_model_checkpoints_dir + 'lastest.ckpt')\n",
    "\n",
    "    def predict(self, image):\n",
    "        lastest_checkpoint = tf.train.latest_checkpoint(devise_model_checkpoints_dir)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, lastest_checkpoint)\n",
    "            image = np.array(image).reshape((1, 256, 256, 3))\n",
    "            feed = {self.alex_model.input_x:image}\n",
    "            image_repesentation = sess.run(self.alex_model.repsentation, feed_dict=feed)\n",
    "            feed = {self.input_x: image_repesentation.T}\n",
    "            label_representation = sess.run(self.prediction, feed_dict=feed)\n",
    "            #\n",
    "            label_representation = np.reshape(label_representation, (200))\n",
    "            print(label_representation.shape)\n",
    "            most_similar = self.word_model.similar_by_vector(label_representation, topn=1)\n",
    "\n",
    "        prediction_label = most_similar[0][0]\n",
    "        return prediction_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = utils.get_image_data()\n",
    "label2int, int2label = utils.get_parameter()\n",
    "numeral_labels = utils.get_numeral_label_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devise model has been initialized\n",
      "step: 1600 loss: 286.484\n",
      "step: 1800 loss: 3522.257\n",
      "step: 2000 loss: 8.668\n",
      "step: 2400 loss: 0.100\n",
      "step: 2800 loss: 1982.249\n",
      "step: 3400 loss: 2322.872\n",
      "step: 4200 loss: 322.985\n",
      "INFO:tensorflow:Restoring parameters from devise_saved_model/lastest.ckpt\n",
      "(200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:102: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hungry'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = DeViSE()\n",
    "d_model.train(train_x, numeral_labels, int2label)\n",
    "prediction = d_model.predict(train_x[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[0])\n",
    "print(int2label[train_y[0].index(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = AlexNet(train_x, train_y)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_size = 200\n",
    "sentences = word2vec.Text8Corpus('text8_data/text8')\n",
    "model = word2vec.Word2Vec(sentences, size=word_embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model.similarity('woman', 'man')\n",
    "print(y1)\n",
    "y2 = model.most_similar('good', topn=1)\n",
    "print(y2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexMNIST(object):\n",
    "    '''\n",
    "    使用给定的训练数据集训练一个AlexNet模型\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 batch_size=64,\n",
    "                 num_units = 128,\n",
    "                 num_classes = 10,\n",
    "                 learning_rate = 0.002,\n",
    "                 num_epoches = 1,\n",
    "                 is_training=True):\n",
    "\n",
    "        self.num_units = num_units\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epoches = num_epoches\n",
    "\n",
    "        if is_training:\n",
    "            self.batch_size = batch_size\n",
    "            self.drop_prob = 0.5\n",
    "        else:\n",
    "            self.batch_size = 1\n",
    "            self.drop_prob = 1.0\n",
    "            \n",
    "        self.build_model()\n",
    "\n",
    "    def build_input(self):\n",
    "        input_x = tf.placeholder(tf.float32, [self.batch_size, 784])\n",
    "        output_y = tf.placeholder(tf.float32, [self.batch_size, self.num_classes], name='output_y')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='drop_keep')\n",
    "        return input_x, output_y, keep_prob\n",
    "\n",
    "    def bulid_CNN(self, input_x):\n",
    "        conv_layer1 = tf.layers.conv2d(inputs=input_x, filters=32, kernel_size=[5, 5], \n",
    "                                       strides=[1, 1], padding='SAME',activation=tf.nn.relu)\n",
    "        pooling_layer1 = tf.layers.max_pooling2d(\n",
    "            inputs=conv_layer1, pool_size=[2, 2], strides=[1, 1])\n",
    "\n",
    "        conv_layer2 = tf.layers.conv2d(inputs=pooling_layer1, filters=32, kernel_size=[5, 5], \n",
    "                                       strides=[1, 1], padding='SAME',activation=tf.nn.relu)\n",
    "        pooling_layer2 = tf.layers.max_pooling2d(\n",
    "            inputs=conv_layer2, pool_size=[2, 2], strides=[1, 1])\n",
    "\n",
    "        cnn_flat = tf.reshape(pooling_layer2, [self.batch_size, -1])\n",
    "        return cnn_flat\n",
    "\n",
    "    def bulid_full_connect(self, cnn_flat, keep_prob):\n",
    "        fc_layer1 = tf.layers.dense(inputs=cnn_flat, units=self.num_units, activation=tf.nn.relu)\n",
    "        fc_layer1 = tf.layers.dropout(fc_layer1, rate=self.drop_prob)\n",
    "        output_layer = tf.layers.dense(inputs=fc_layer1, units=self.num_classes, activation=None)\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "    def bulid_loss(self, logits, targets):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        return loss\n",
    "\n",
    "    def bulid_optimizer(self, loss):\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "        return optimizer\n",
    "\n",
    "    def bulid_accuracy(self, logits, targets):\n",
    "        equality = tf.equal(tf.argmax(logits, axis=1), tf.argmax(targets, axis=1))\n",
    "        equality = tf.cast(equality, tf.float32)\n",
    "        accuracy = tf.reduce_mean(equality)\n",
    "        return accuracy\n",
    "\n",
    "    def build_model(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.input_x, self.output_y, self.keep_prob = self.build_input()\n",
    "        self.reshape_x = tf.reshape(self.input_x, [self.batch_size, 28, 28, 1])\n",
    "        self.cnn_padding = self.bulid_CNN(self.reshape_x)\n",
    "        self.output_layer = self.bulid_full_connect(self.cnn_padding, self.keep_prob)\n",
    "        self.loss = self.bulid_loss(self.output_layer, self.output_y)\n",
    "        self.optimizer = self.bulid_optimizer(self.loss)\n",
    "        self.accuracy = self.bulid_accuracy(self.output_layer, self.output_y)\n",
    "\n",
    "    def train(self,data=None):\n",
    "        saver = tf.train.Saver()\n",
    "        #模型训练并将训练的结果保存在本地\n",
    "        with tf.Session() as sess:\n",
    "            print(\"AlexNet model training begins....\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            global_steps = 0\n",
    "            for epoch in range(self.num_epoches):\n",
    "                for step in range(5000):\n",
    "                    batch_x, batch_y = data.train.next_batch(self.batch_size)\n",
    "                    feed = {self.input_x: batch_x,\n",
    "                        self.output_y: batch_y,\n",
    "                        self.keep_prob: self.drop_prob}\n",
    "                    show_loss, show_accu, _ = sess.run(\n",
    "                        [self.loss, self.accuracy, self.optimizer], feed_dict=feed)\n",
    "\n",
    "                    if step % show_every_n == 0:\n",
    "                        print('epoch: {}/{}..'.format(epoch+1, self.num_epoches+1),\n",
    "                              'global_step: {}..'.format(global_steps),\n",
    "                              'loss: {:.3f}..'.format(show_loss),\n",
    "                              'accuracy: {:.2f}..'.format(show_accu))\n",
    "        print('training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "def get_MNIST():\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    return mnist\n",
    "mnist = get_MNIST()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
